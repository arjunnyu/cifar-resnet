{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "754ada65-9982-424c-bdd2-ea841548122f",
   "metadata": {},
   "source": [
    "# CS-GY 6953 Deep Learning Mini-Project Shallow network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76a3877-7d5a-4010-ae7a-f86c4ca76eb7",
   "metadata": {},
   "source": [
    "Task: Building a ResNet model on CIFAR-10 with a constraint of 5 million parameters maximum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf84c73-16aa-40c8-b501-91f80a880e46",
   "metadata": {},
   "source": [
    "## 1. Starting Simple: Load the CIFAR-10 dataset and build the first shallow ResNet network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b1a5ae-1f82-4c84-80df-1fa976d2137b",
   "metadata": {},
   "source": [
    "Create the data loaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3900ea2-22b7-408f-9263-aadc09f60388",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.14.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (9.3.0)\n",
      "Requirement already satisfied: torch==1.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.13.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: requests in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torchvision) (2.28.1)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n",
      "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: torchsummary in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision\n",
    "!pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6f9fbc9-d33d-4196-9673-eb4c90afecdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5c5cb1-86e5-4384-aed6-aef190abb6f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "# There are more functions for augmentation.\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',train=False, download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eca3e2-d113-4aa0-9a2a-bddea9eae4c9",
   "metadata": {},
   "source": [
    "Construct the ResNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1177fd06-92df-4340-8f6e-f5a1d5247c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchsummary import summary\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72f709c-fdaa-4f0c-baf6-a7e4e1a44d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module): # A residual block with 2 convolutional layers and a skip connection.\n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes,      # Number of channels in the input image\n",
    "                               planes,         # Number of output channels\n",
    "                               kernel_size=3,  # Size of the convolution filter\n",
    "                               stride=stride,  # Stride of the convolution\n",
    "                               padding=1,      # Padding added to all four sides of the input, int or {'valid', 'same'}, etc.\n",
    "                               # padding_mode={'zeros', 'reflect', 'replicate', 'circular'}\n",
    "                               bias=False)     # If true, adds a learnable bias ot the output.\n",
    "        self.bn1 = nn.BatchNorm2d(planes)      # Other parameters include eps, momentum, affine, etc.\n",
    "                                               # affine=True: affine parameters being learnable.\n",
    "        self.conv2 = nn.Conv2d(planes, \n",
    "                               planes, \n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.shortcut = nn.Sequential()        # A sequentil wrapper of layers.\n",
    "        # If the dimentions of skip connection input and output don't match, do the following.\n",
    "        # As an alternative solution, zero-padding is also proposed in the paper.\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_planes, \n",
    "                                                    self.expansion*planes, \n",
    "                                                    kernel_size=1, \n",
    "                                                    stride=stride, \n",
    "                                                    bias=False),\n",
    "                                          nn.BatchNorm2d(self.expansion*planes))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3876545-5fb9-4eff-9124-ec4043cc7dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 64, \n",
    "                               kernel_size=3, \n",
    "                               stride=1, \n",
    "                               padding=1, \n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 96, num_blocks[3], stride=2)\n",
    "        self.layer5 = self._make_layer(block, 128, num_blocks[4], stride=2)\n",
    "        self.layer6 = self._make_layer(block, 160, num_blocks[5], stride=2)\n",
    "        self.layer7 = self._make_layer(block, 192, num_blocks[6], stride=2)\n",
    "        self.layer8 = self._make_layer(block, 220, num_blocks[6], stride=2)\n",
    "        # self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "        self.linear = nn.Linear(220*block.expansion, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes*block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.layer5(out)\n",
    "        out = self.layer6(out)\n",
    "        out = self.layer7(out)\n",
    "        out = self.layer8(out)\n",
    "        # out = F.avg_pool2d(out, 4)\n",
    "        out = F.avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "464d0c5b-a7ed-420e-a87c-2e37ee0ba034",
   "metadata": {},
   "outputs": [],
   "source": [
    " model = ResNet(BasicBlock, [2,2,2,2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ad8928-674b-46d1-b6f1-0aeea92f1366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 16, 32, 32]           9,216\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "            Conv2d-5           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-6           [-1, 16, 32, 32]              32\n",
      "            Conv2d-7           [-1, 16, 32, 32]           1,024\n",
      "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
      "        BasicBlock-9           [-1, 16, 32, 32]               0\n",
      "           Conv2d-10           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-11           [-1, 16, 32, 32]              32\n",
      "           Conv2d-12           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-13           [-1, 16, 32, 32]              32\n",
      "       BasicBlock-14           [-1, 16, 32, 32]               0\n",
      "           Conv2d-15           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-16           [-1, 32, 16, 16]              64\n",
      "           Conv2d-17           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-18           [-1, 32, 16, 16]              64\n",
      "           Conv2d-19           [-1, 32, 16, 16]             512\n",
      "      BatchNorm2d-20           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-21           [-1, 32, 16, 16]               0\n",
      "           Conv2d-22           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-23           [-1, 32, 16, 16]              64\n",
      "           Conv2d-24           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-25           [-1, 32, 16, 16]              64\n",
      "       BasicBlock-26           [-1, 32, 16, 16]               0\n",
      "           Conv2d-27             [-1, 64, 8, 8]          18,432\n",
      "      BatchNorm2d-28             [-1, 64, 8, 8]             128\n",
      "           Conv2d-29             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-30             [-1, 64, 8, 8]             128\n",
      "           Conv2d-31             [-1, 64, 8, 8]           2,048\n",
      "      BatchNorm2d-32             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-33             [-1, 64, 8, 8]               0\n",
      "           Conv2d-34             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-35             [-1, 64, 8, 8]             128\n",
      "           Conv2d-36             [-1, 64, 8, 8]          36,864\n",
      "      BatchNorm2d-37             [-1, 64, 8, 8]             128\n",
      "       BasicBlock-38             [-1, 64, 8, 8]               0\n",
      "           Conv2d-39             [-1, 96, 4, 4]          55,296\n",
      "      BatchNorm2d-40             [-1, 96, 4, 4]             192\n",
      "           Conv2d-41             [-1, 96, 4, 4]          82,944\n",
      "      BatchNorm2d-42             [-1, 96, 4, 4]             192\n",
      "           Conv2d-43             [-1, 96, 4, 4]           6,144\n",
      "      BatchNorm2d-44             [-1, 96, 4, 4]             192\n",
      "       BasicBlock-45             [-1, 96, 4, 4]               0\n",
      "           Conv2d-46             [-1, 96, 4, 4]          82,944\n",
      "      BatchNorm2d-47             [-1, 96, 4, 4]             192\n",
      "           Conv2d-48             [-1, 96, 4, 4]          82,944\n",
      "      BatchNorm2d-49             [-1, 96, 4, 4]             192\n",
      "       BasicBlock-50             [-1, 96, 4, 4]               0\n",
      "           Conv2d-51            [-1, 128, 2, 2]         110,592\n",
      "      BatchNorm2d-52            [-1, 128, 2, 2]             256\n",
      "           Conv2d-53            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-54            [-1, 128, 2, 2]             256\n",
      "           Conv2d-55            [-1, 128, 2, 2]          12,288\n",
      "      BatchNorm2d-56            [-1, 128, 2, 2]             256\n",
      "       BasicBlock-57            [-1, 128, 2, 2]               0\n",
      "           Conv2d-58            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-59            [-1, 128, 2, 2]             256\n",
      "           Conv2d-60            [-1, 128, 2, 2]         147,456\n",
      "      BatchNorm2d-61            [-1, 128, 2, 2]             256\n",
      "       BasicBlock-62            [-1, 128, 2, 2]               0\n",
      "           Conv2d-63            [-1, 160, 1, 1]         184,320\n",
      "      BatchNorm2d-64            [-1, 160, 1, 1]             320\n",
      "           Conv2d-65            [-1, 160, 1, 1]         230,400\n",
      "      BatchNorm2d-66            [-1, 160, 1, 1]             320\n",
      "           Conv2d-67            [-1, 160, 1, 1]          20,480\n",
      "      BatchNorm2d-68            [-1, 160, 1, 1]             320\n",
      "       BasicBlock-69            [-1, 160, 1, 1]               0\n",
      "           Conv2d-70            [-1, 160, 1, 1]         230,400\n",
      "      BatchNorm2d-71            [-1, 160, 1, 1]             320\n",
      "           Conv2d-72            [-1, 160, 1, 1]         230,400\n",
      "      BatchNorm2d-73            [-1, 160, 1, 1]             320\n",
      "       BasicBlock-74            [-1, 160, 1, 1]               0\n",
      "           Conv2d-75            [-1, 192, 1, 1]         276,480\n",
      "      BatchNorm2d-76            [-1, 192, 1, 1]             384\n",
      "           Conv2d-77            [-1, 192, 1, 1]         331,776\n",
      "      BatchNorm2d-78            [-1, 192, 1, 1]             384\n",
      "           Conv2d-79            [-1, 192, 1, 1]          30,720\n",
      "      BatchNorm2d-80            [-1, 192, 1, 1]             384\n",
      "       BasicBlock-81            [-1, 192, 1, 1]               0\n",
      "           Conv2d-82            [-1, 192, 1, 1]         331,776\n",
      "      BatchNorm2d-83            [-1, 192, 1, 1]             384\n",
      "           Conv2d-84            [-1, 192, 1, 1]         331,776\n",
      "      BatchNorm2d-85            [-1, 192, 1, 1]             384\n",
      "       BasicBlock-86            [-1, 192, 1, 1]               0\n",
      "           Conv2d-87            [-1, 220, 1, 1]         380,160\n",
      "      BatchNorm2d-88            [-1, 220, 1, 1]             440\n",
      "           Conv2d-89            [-1, 220, 1, 1]         435,600\n",
      "      BatchNorm2d-90            [-1, 220, 1, 1]             440\n",
      "           Conv2d-91            [-1, 220, 1, 1]          42,240\n",
      "      BatchNorm2d-92            [-1, 220, 1, 1]             440\n",
      "       BasicBlock-93            [-1, 220, 1, 1]               0\n",
      "           Conv2d-94            [-1, 220, 1, 1]         435,600\n",
      "      BatchNorm2d-95            [-1, 220, 1, 1]             440\n",
      "           Conv2d-96            [-1, 220, 1, 1]         435,600\n",
      "      BatchNorm2d-97            [-1, 220, 1, 1]             440\n",
      "       BasicBlock-98            [-1, 220, 1, 1]               0\n",
      "           Linear-99                   [-1, 10]           2,210\n",
      "================================================================\n",
      "Total params: 4,997,386\n",
      "Trainable params: 4,997,386\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 3.86\n",
      "Params size (MB): 19.06\n",
      "Estimated Total Size (MB): 22.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, 32, 32), device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb7f434-38d2-49a9-a103-9f1f7f4861b5",
   "metadata": {},
   "source": [
    "Note: No non-linearity in the fully connected part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6b7f869-6337-477c-89f9-1afc818f3e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device is cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"The device is {device}\")\n",
    "model = model.to(device)\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1787f0db-efb6-4457-9ec4-6bd1bae00822",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), \n",
    "                      lr=0.1, \n",
    "                      momentum=0.9, \n",
    "                      weight_decay=5e-4)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"max\", factor=0.1, patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2cf8682-e9df-43d9-aede-d24cc7372858",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chk_name =  'deep_8layer_ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bee0f2e-916c-4d28-9fdf-c9006aee48e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    print('\\nEpoch: %d'%epoch)\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct, total = 0, 0\n",
    "    for (inputs, targets) in trainloader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "    acc = correct/total*100\n",
    "    train_loss /= total\n",
    "    print(f\"Train | Loss: {round(train_loss, 4)} | Acc: {round(acc, 2)}\")\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(acc)\n",
    "\n",
    "def test(epoch):\n",
    "    global train_losses, test_losses, train_accs, test_accs, lrs, best_acc\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for (inputs, targets) in testloader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    acc = correct/total*100\n",
    "    test_loss /= total\n",
    "    print(f\"Test  | Loss: {round(test_loss, 4)} | Acc: {round(acc, 2)}\")\n",
    "    test_losses.append(test_loss)\n",
    "    test_accs.append(acc)\n",
    "    \n",
    "    state = {'model': model.state_dict(),\n",
    "             'train_loss': train_losses,\n",
    "             'test_loss': test_losses,\n",
    "             'train_acc': train_accs,\n",
    "             'test_acc': test_accs,\n",
    "             'lrs':lrs,\n",
    "             'epoch': epoch}\n",
    "    torch.save(state, './checkpoint/'+model_chk_name+'.pth')\n",
    "    if acc > best_acc:\n",
    "        torch.save(state, './checkpoint/'+model_chk_name+'_best.pth')\n",
    "        best_acc = acc\n",
    "\n",
    "if not os.path.isdir('checkpoint'):\n",
    "    os.mkdir('checkpoint')\n",
    "state = {'model': model.state_dict(),\n",
    "         'train_loss': [],\n",
    "         'test_loss': [],\n",
    "         'train_acc': [],\n",
    "         'test_acc': [],\n",
    "         'lr':[],\n",
    "         'epoch': -1}\n",
    "torch.save(state, './checkpoint/'+model_chk_name+'.pth')\n",
    "torch.save(state, './checkpoint/'+model_chk_name+'_best.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba29e0a-84a0-4501-9871-9c2d7ac04b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "251f6fce-e3f0-4c06-89d4-8873fb8b751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Starting epoch :  -1\n",
      "\n",
      " Starting best_acc :  0.0\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('./checkpoint/'+model_chk_name+'.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "train_losses = checkpoint['train_loss']\n",
    "test_losses = checkpoint['test_loss']\n",
    "train_accs = checkpoint['train_acc']\n",
    "test_accs = checkpoint['test_acc']\n",
    "lrs = checkpoint['lr']\n",
    "best_acc = 0.0 if not test_accs else max(test_accs)\n",
    "start_epoch = checkpoint['epoch']\n",
    "print(\"\\n Starting epoch : \",start_epoch)\n",
    "print(\"\\n Starting best_acc : \",best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64ae2d03-150a-473a-9c8c-8be1102ae54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "Train | Loss: 0.0168 | Acc: 21.98\n",
      "Test  | Loss: 0.0145 | Acc: 29.58\n",
      "\n",
      "Epoch: 1\n",
      "Train | Loss: 0.0136 | Acc: 34.72\n",
      "Test  | Loss: 0.0125 | Acc: 41.68\n",
      "\n",
      "Epoch: 2\n",
      "Train | Loss: 0.012 | Acc: 43.49\n",
      "Test  | Loss: 0.0127 | Acc: 41.98\n",
      "\n",
      "Epoch: 3\n",
      "Train | Loss: 0.0106 | Acc: 50.89\n",
      "Test  | Loss: 0.0098 | Acc: 54.32\n",
      "\n",
      "Epoch: 4\n",
      "Train | Loss: 0.0093 | Acc: 57.76\n",
      "Test  | Loss: 0.0116 | Acc: 51.94\n",
      "\n",
      "Epoch: 5\n",
      "Train | Loss: 0.0083 | Acc: 62.67\n",
      "Test  | Loss: 0.0084 | Acc: 62.17\n",
      "\n",
      "Epoch: 6\n",
      "Train | Loss: 0.0075 | Acc: 66.47\n",
      "Test  | Loss: 0.0075 | Acc: 66.8\n",
      "\n",
      "Epoch: 7\n",
      "Train | Loss: 0.0069 | Acc: 69.48\n",
      "Test  | Loss: 0.0079 | Acc: 66.77\n",
      "\n",
      "Epoch: 8\n",
      "Train | Loss: 0.0064 | Acc: 71.91\n",
      "Test  | Loss: 0.0086 | Acc: 64.46\n",
      "\n",
      "Epoch: 9\n",
      "Train | Loss: 0.0061 | Acc: 73.43\n",
      "Test  | Loss: 0.0064 | Acc: 72.62\n",
      "\n",
      "Epoch: 10\n",
      "Train | Loss: 0.0057 | Acc: 75.29\n",
      "Test  | Loss: 0.0084 | Acc: 67.74\n",
      "\n",
      "Epoch: 11\n",
      "Train | Loss: 0.0056 | Acc: 75.84\n",
      "Test  | Loss: 0.0063 | Acc: 73.03\n",
      "\n",
      "Epoch: 12\n",
      "Train | Loss: 0.0054 | Acc: 76.65\n",
      "Test  | Loss: 0.0088 | Acc: 63.83\n",
      "\n",
      "Epoch: 13\n",
      "Train | Loss: 0.0053 | Acc: 77.3\n",
      "Test  | Loss: 0.0087 | Acc: 63.71\n",
      "\n",
      "Epoch: 14\n",
      "Train | Loss: 0.0051 | Acc: 78.05\n",
      "Test  | Loss: 0.0063 | Acc: 74.3\n",
      "\n",
      "Epoch: 15\n",
      "Train | Loss: 0.0051 | Acc: 78.17\n",
      "Test  | Loss: 0.0057 | Acc: 75.1\n",
      "\n",
      "Epoch: 16\n",
      "Train | Loss: 0.005 | Acc: 78.51\n",
      "Test  | Loss: 0.006 | Acc: 74.55\n",
      "\n",
      "Epoch: 17\n",
      "Train | Loss: 0.0049 | Acc: 79.21\n",
      "Test  | Loss: 0.0054 | Acc: 77.24\n",
      "\n",
      "Epoch: 18\n",
      "Train | Loss: 0.0048 | Acc: 79.42\n",
      "Test  | Loss: 0.0061 | Acc: 74.53\n",
      "\n",
      "Epoch: 19\n",
      "Train | Loss: 0.0049 | Acc: 79.12\n",
      "Test  | Loss: 0.0058 | Acc: 76.01\n",
      "\n",
      "Epoch: 20\n",
      "Train | Loss: 0.0047 | Acc: 79.89\n",
      "Test  | Loss: 0.0071 | Acc: 72.11\n",
      "\n",
      "Epoch: 21\n",
      "Train | Loss: 0.0047 | Acc: 79.93\n",
      "Test  | Loss: 0.0061 | Acc: 74.31\n",
      "\n",
      "Epoch: 22\n",
      "Train | Loss: 0.0046 | Acc: 80.42\n",
      "Test  | Loss: 0.0057 | Acc: 75.91\n",
      "\n",
      "Epoch: 23\n",
      "Train | Loss: 0.0046 | Acc: 80.16\n",
      "Test  | Loss: 0.0066 | Acc: 74.15\n",
      "\n",
      "Epoch: 24\n",
      "Train | Loss: 0.0046 | Acc: 80.45\n",
      "Test  | Loss: 0.006 | Acc: 75.24\n",
      "\n",
      "Epoch: 25\n",
      "Train | Loss: 0.0046 | Acc: 80.68\n",
      "Test  | Loss: 0.0063 | Acc: 74.56\n",
      "\n",
      "Epoch: 26\n",
      "Train | Loss: 0.0045 | Acc: 80.79\n",
      "Test  | Loss: 0.0052 | Acc: 78.71\n",
      "\n",
      "Epoch: 27\n",
      "Train | Loss: 0.0045 | Acc: 80.78\n",
      "Test  | Loss: 0.0057 | Acc: 76.37\n",
      "\n",
      "Epoch: 28\n",
      "Train | Loss: 0.0045 | Acc: 80.88\n",
      "Test  | Loss: 0.006 | Acc: 74.26\n",
      "\n",
      "Epoch: 29\n",
      "Train | Loss: 0.0044 | Acc: 81.07\n",
      "Test  | Loss: 0.0063 | Acc: 73.37\n",
      "\n",
      "Epoch: 30\n",
      "Train | Loss: 0.0044 | Acc: 81.23\n",
      "Test  | Loss: 0.0058 | Acc: 76.99\n",
      "\n",
      "Epoch: 31\n",
      "Train | Loss: 0.0044 | Acc: 81.23\n",
      "Test  | Loss: 0.0069 | Acc: 70.96\n",
      "\n",
      "Epoch: 32\n",
      "Train | Loss: 0.0044 | Acc: 81.04\n",
      "Test  | Loss: 0.0048 | Acc: 79.67\n",
      "\n",
      "Epoch: 33\n",
      "Train | Loss: 0.0044 | Acc: 81.3\n",
      "Test  | Loss: 0.0055 | Acc: 77.84\n",
      "\n",
      "Epoch: 34\n",
      "Train | Loss: 0.0043 | Acc: 81.56\n",
      "Test  | Loss: 0.006 | Acc: 74.66\n",
      "\n",
      "Epoch: 35\n",
      "Train | Loss: 0.0044 | Acc: 81.23\n",
      "Test  | Loss: 0.005 | Acc: 78.64\n",
      "\n",
      "Epoch: 36\n",
      "Train | Loss: 0.0043 | Acc: 81.67\n",
      "Test  | Loss: 0.0053 | Acc: 77.23\n",
      "\n",
      "Epoch: 37\n",
      "Train | Loss: 0.0043 | Acc: 81.92\n",
      "Test  | Loss: 0.006 | Acc: 73.83\n",
      "\n",
      "Epoch: 38\n",
      "Train | Loss: 0.0043 | Acc: 81.75\n",
      "Test  | Loss: 0.0078 | Acc: 72.13\n",
      "\n",
      "Epoch: 39\n",
      "Train | Loss: 0.0043 | Acc: 81.67\n",
      "Test  | Loss: 0.0051 | Acc: 78.55\n",
      "\n",
      "Epoch: 40\n",
      "Train | Loss: 0.0043 | Acc: 81.9\n",
      "Test  | Loss: 0.0069 | Acc: 73.3\n",
      "\n",
      "Epoch: 41\n",
      "Train | Loss: 0.0042 | Acc: 82.05\n",
      "Test  | Loss: 0.0072 | Acc: 71.72\n",
      "\n",
      "Epoch: 42\n",
      "Train | Loss: 0.0043 | Acc: 81.72\n",
      "Test  | Loss: 0.0071 | Acc: 71.79\n",
      "\n",
      "Epoch: 43\n",
      "Train | Loss: 0.0042 | Acc: 82.05\n",
      "Test  | Loss: 0.006 | Acc: 75.91\n",
      "\n",
      "Epoch: 44\n",
      "Train | Loss: 0.0043 | Acc: 81.86\n",
      "Test  | Loss: 0.0055 | Acc: 77.98\n",
      "\n",
      "Epoch: 45\n",
      "Train | Loss: 0.0042 | Acc: 81.84\n",
      "Test  | Loss: 0.0045 | Acc: 80.77\n",
      "\n",
      "Epoch: 46\n",
      "Train | Loss: 0.0042 | Acc: 82.11\n",
      "Test  | Loss: 0.0055 | Acc: 76.94\n",
      "\n",
      "Epoch: 47\n",
      "Train | Loss: 0.0042 | Acc: 82.0\n",
      "Test  | Loss: 0.0062 | Acc: 73.96\n",
      "\n",
      "Epoch: 48\n",
      "Train | Loss: 0.0042 | Acc: 82.27\n",
      "Test  | Loss: 0.0051 | Acc: 78.86\n",
      "\n",
      "Epoch: 49\n",
      "Train | Loss: 0.0042 | Acc: 81.96\n",
      "Test  | Loss: 0.0056 | Acc: 77.43\n",
      "\n",
      "Epoch: 50\n",
      "Train | Loss: 0.0041 | Acc: 82.3\n",
      "Test  | Loss: 0.0057 | Acc: 76.42\n",
      "\n",
      "Epoch: 51\n",
      "Train | Loss: 0.0042 | Acc: 82.21\n",
      "Test  | Loss: 0.0048 | Acc: 80.1\n",
      "\n",
      "Epoch: 52\n",
      "Train | Loss: 0.0042 | Acc: 82.0\n",
      "Test  | Loss: 0.0049 | Acc: 79.95\n",
      "\n",
      "Epoch: 53\n",
      "Train | Loss: 0.0041 | Acc: 82.3\n",
      "Test  | Loss: 0.0047 | Acc: 80.19\n",
      "\n",
      "Epoch: 54\n",
      "Train | Loss: 0.0041 | Acc: 82.31\n",
      "Test  | Loss: 0.0058 | Acc: 76.83\n",
      "\n",
      "Epoch: 55\n",
      "Train | Loss: 0.0041 | Acc: 82.43\n",
      "Test  | Loss: 0.0055 | Acc: 76.84\n",
      "\n",
      "Epoch: 56\n",
      "Train | Loss: 0.0042 | Acc: 82.07\n",
      "Test  | Loss: 0.0051 | Acc: 79.37\n",
      "\n",
      "Epoch: 57\n",
      "Train | Loss: 0.0041 | Acc: 82.5\n",
      "Test  | Loss: 0.0052 | Acc: 78.09\n",
      "\n",
      "Epoch: 58\n",
      "Train | Loss: 0.0041 | Acc: 82.33\n",
      "Test  | Loss: 0.005 | Acc: 79.42\n",
      "\n",
      "Epoch: 59\n",
      "Train | Loss: 0.0041 | Acc: 82.62\n",
      "Test  | Loss: 0.0048 | Acc: 79.68\n",
      "\n",
      "Epoch: 60\n",
      "Train | Loss: 0.0041 | Acc: 82.53\n",
      "Test  | Loss: 0.0092 | Acc: 64.48\n",
      "\n",
      "Epoch: 61\n",
      "Train | Loss: 0.0041 | Acc: 82.75\n",
      "Test  | Loss: 0.0049 | Acc: 79.2\n",
      "\n",
      "Epoch: 62\n",
      "Train | Loss: 0.0027 | Acc: 88.27\n",
      "Test  | Loss: 0.0027 | Acc: 88.32\n",
      "\n",
      "Epoch: 63\n",
      "Train | Loss: 0.0023 | Acc: 90.07\n",
      "Test  | Loss: 0.0026 | Acc: 89.06\n",
      "\n",
      "Epoch: 64\n",
      "Train | Loss: 0.0022 | Acc: 90.74\n",
      "Test  | Loss: 0.0026 | Acc: 89.51\n",
      "\n",
      "Epoch: 65\n",
      "Train | Loss: 0.0021 | Acc: 91.26\n",
      "Test  | Loss: 0.0025 | Acc: 89.64\n",
      "\n",
      "Epoch: 66\n",
      "Train | Loss: 0.002 | Acc: 91.38\n",
      "Test  | Loss: 0.0025 | Acc: 89.65\n",
      "\n",
      "Epoch: 67\n",
      "Train | Loss: 0.0019 | Acc: 91.72\n",
      "Test  | Loss: 0.0025 | Acc: 89.95\n",
      "\n",
      "Epoch: 68\n",
      "Train | Loss: 0.0018 | Acc: 92.08\n",
      "Test  | Loss: 0.0025 | Acc: 89.43\n",
      "\n",
      "Epoch: 69\n",
      "Train | Loss: 0.0018 | Acc: 92.33\n",
      "Test  | Loss: 0.0024 | Acc: 89.93\n",
      "\n",
      "Epoch: 70\n",
      "Train | Loss: 0.0018 | Acc: 92.35\n",
      "Test  | Loss: 0.0025 | Acc: 89.27\n",
      "\n",
      "Epoch: 71\n",
      "Train | Loss: 0.0017 | Acc: 92.46\n",
      "Test  | Loss: 0.0024 | Acc: 89.76\n",
      "\n",
      "Epoch: 72\n",
      "Train | Loss: 0.0017 | Acc: 92.78\n",
      "Test  | Loss: 0.0024 | Acc: 89.91\n",
      "\n",
      "Epoch: 73\n",
      "Train | Loss: 0.0016 | Acc: 93.04\n",
      "Test  | Loss: 0.0026 | Acc: 89.37\n",
      "\n",
      "Epoch: 74\n",
      "Train | Loss: 0.0016 | Acc: 93.16\n",
      "Test  | Loss: 0.0025 | Acc: 89.57\n",
      "\n",
      "Epoch: 75\n",
      "Train | Loss: 0.0015 | Acc: 93.14\n",
      "Test  | Loss: 0.0026 | Acc: 88.92\n",
      "\n",
      "Epoch: 76\n",
      "Train | Loss: 0.0015 | Acc: 93.38\n",
      "Test  | Loss: 0.0027 | Acc: 89.08\n",
      "\n",
      "Epoch: 77\n",
      "Train | Loss: 0.0015 | Acc: 93.28\n",
      "Test  | Loss: 0.0026 | Acc: 89.4\n",
      "\n",
      "Epoch: 78\n",
      "Train | Loss: 0.0015 | Acc: 93.37\n",
      "Test  | Loss: 0.0026 | Acc: 89.41\n",
      "\n",
      "Epoch: 79\n",
      "Train | Loss: 0.0015 | Acc: 93.38\n",
      "Test  | Loss: 0.0025 | Acc: 89.7\n",
      "\n",
      "Epoch: 80\n",
      "Train | Loss: 0.0015 | Acc: 93.43\n",
      "Test  | Loss: 0.0028 | Acc: 88.62\n",
      "\n",
      "Epoch: 81\n",
      "Train | Loss: 0.0015 | Acc: 93.59\n",
      "Test  | Loss: 0.0026 | Acc: 89.47\n",
      "\n",
      "Epoch: 82\n",
      "Train | Loss: 0.0015 | Acc: 93.47\n",
      "Test  | Loss: 0.0027 | Acc: 89.24\n",
      "\n",
      "Epoch: 83\n",
      "Train | Loss: 0.0015 | Acc: 93.63\n",
      "Test  | Loss: 0.0027 | Acc: 88.94\n",
      "\n",
      "Epoch: 84\n",
      "Train | Loss: 0.0011 | Acc: 95.03\n",
      "Test  | Loss: 0.0022 | Acc: 90.84\n",
      "\n",
      "Epoch: 85\n",
      "Train | Loss: 0.001 | Acc: 95.72\n",
      "Test  | Loss: 0.0022 | Acc: 91.05\n",
      "\n",
      "Epoch: 86\n",
      "Train | Loss: 0.001 | Acc: 95.93\n",
      "Test  | Loss: 0.0022 | Acc: 91.18\n",
      "\n",
      "Epoch: 87\n",
      "Train | Loss: 0.0009 | Acc: 95.93\n",
      "Test  | Loss: 0.0022 | Acc: 91.21\n",
      "\n",
      "Epoch: 88\n",
      "Train | Loss: 0.0009 | Acc: 96.15\n",
      "Test  | Loss: 0.0022 | Acc: 91.25\n",
      "\n",
      "Epoch: 89\n",
      "Train | Loss: 0.0009 | Acc: 96.3\n",
      "Test  | Loss: 0.0022 | Acc: 91.2\n",
      "\n",
      "Epoch: 90\n",
      "Train | Loss: 0.0009 | Acc: 96.39\n",
      "Test  | Loss: 0.0023 | Acc: 91.14\n",
      "\n",
      "Epoch: 91\n",
      "Train | Loss: 0.0008 | Acc: 96.36\n",
      "Test  | Loss: 0.0023 | Acc: 91.1\n",
      "\n",
      "Epoch: 92\n",
      "Train | Loss: 0.0008 | Acc: 96.46\n",
      "Test  | Loss: 0.0023 | Acc: 91.2\n",
      "\n",
      "Epoch: 93\n",
      "Train | Loss: 0.0008 | Acc: 96.52\n",
      "Test  | Loss: 0.0023 | Acc: 91.25\n",
      "\n",
      "Epoch: 94\n",
      "Train | Loss: 0.0008 | Acc: 96.49\n",
      "Test  | Loss: 0.0023 | Acc: 91.15\n",
      "\n",
      "Epoch: 95\n",
      "Train | Loss: 0.0008 | Acc: 96.55\n",
      "Test  | Loss: 0.0024 | Acc: 91.08\n",
      "\n",
      "Epoch: 96\n",
      "Train | Loss: 0.0008 | Acc: 96.73\n",
      "Test  | Loss: 0.0023 | Acc: 91.12\n",
      "\n",
      "Epoch: 97\n",
      "Train | Loss: 0.0007 | Acc: 96.85\n",
      "Test  | Loss: 0.0023 | Acc: 91.03\n",
      "\n",
      "Epoch: 98\n",
      "Train | Loss: 0.0008 | Acc: 96.71\n",
      "Test  | Loss: 0.0024 | Acc: 91.07\n",
      "\n",
      "Epoch: 99\n",
      "Train | Loss: 0.0007 | Acc: 96.81\n",
      "Test  | Loss: 0.0023 | Acc: 91.17\n",
      "\n",
      "Epoch: 100\n",
      "Train | Loss: 0.0007 | Acc: 96.9\n",
      "Test  | Loss: 0.0024 | Acc: 91.21\n",
      "\n",
      "Epoch: 101\n",
      "Train | Loss: 0.0007 | Acc: 97.06\n",
      "Test  | Loss: 0.0024 | Acc: 91.21\n",
      "\n",
      "Epoch: 102\n",
      "Train | Loss: 0.0007 | Acc: 96.95\n",
      "Test  | Loss: 0.0025 | Acc: 91.29\n",
      "\n",
      "Epoch: 103\n",
      "Train | Loss: 0.0007 | Acc: 97.14\n",
      "Test  | Loss: 0.0024 | Acc: 91.04\n",
      "\n",
      "Epoch: 104\n",
      "Train | Loss: 0.0007 | Acc: 97.09\n",
      "Test  | Loss: 0.0024 | Acc: 91.19\n",
      "\n",
      "Epoch: 105\n",
      "Train | Loss: 0.0007 | Acc: 97.15\n",
      "Test  | Loss: 0.0024 | Acc: 91.16\n",
      "\n",
      "Epoch: 106\n",
      "Train | Loss: 0.0007 | Acc: 97.16\n",
      "Test  | Loss: 0.0024 | Acc: 91.33\n",
      "\n",
      "Epoch: 107\n",
      "Train | Loss: 0.0007 | Acc: 97.06\n",
      "Test  | Loss: 0.0024 | Acc: 91.18\n",
      "\n",
      "Epoch: 108\n",
      "Train | Loss: 0.0006 | Acc: 97.33\n",
      "Test  | Loss: 0.0024 | Acc: 91.17\n",
      "\n",
      "Epoch: 109\n",
      "Train | Loss: 0.0006 | Acc: 97.34\n",
      "Test  | Loss: 0.0025 | Acc: 91.11\n",
      "\n",
      "Epoch: 110\n",
      "Train | Loss: 0.0006 | Acc: 97.14\n",
      "Test  | Loss: 0.0024 | Acc: 90.95\n",
      "\n",
      "Epoch: 111\n",
      "Train | Loss: 0.0006 | Acc: 97.32\n",
      "Test  | Loss: 0.0024 | Acc: 91.4\n",
      "\n",
      "Epoch: 112\n",
      "Train | Loss: 0.0006 | Acc: 97.38\n",
      "Test  | Loss: 0.0025 | Acc: 91.28\n",
      "\n",
      "Epoch: 113\n",
      "Train | Loss: 0.0006 | Acc: 97.4\n",
      "Test  | Loss: 0.0025 | Acc: 91.35\n",
      "\n",
      "Epoch: 114\n",
      "Train | Loss: 0.0006 | Acc: 97.38\n",
      "Test  | Loss: 0.0025 | Acc: 91.23\n",
      "\n",
      "Epoch: 115\n",
      "Train | Loss: 0.0006 | Acc: 97.46\n",
      "Test  | Loss: 0.0024 | Acc: 91.13\n",
      "\n",
      "Epoch: 116\n",
      "Train | Loss: 0.0006 | Acc: 97.43\n",
      "Test  | Loss: 0.0025 | Acc: 91.18\n",
      "\n",
      "Epoch: 117\n",
      "Train | Loss: 0.0006 | Acc: 97.45\n",
      "Test  | Loss: 0.0025 | Acc: 91.07\n",
      "\n",
      "Epoch: 118\n",
      "Train | Loss: 0.0006 | Acc: 97.54\n",
      "Test  | Loss: 0.0025 | Acc: 91.05\n",
      "\n",
      "Epoch: 119\n",
      "Train | Loss: 0.0006 | Acc: 97.55\n",
      "Test  | Loss: 0.0026 | Acc: 91.15\n",
      "\n",
      "Epoch: 120\n",
      "Train | Loss: 0.0006 | Acc: 97.54\n",
      "Test  | Loss: 0.0025 | Acc: 91.05\n",
      "\n",
      "Epoch: 121\n",
      "Train | Loss: 0.0006 | Acc: 97.59\n",
      "Test  | Loss: 0.0026 | Acc: 91.09\n",
      "\n",
      "Epoch: 122\n",
      "Train | Loss: 0.0005 | Acc: 97.67\n",
      "Test  | Loss: 0.0026 | Acc: 91.18\n",
      "\n",
      "Epoch: 123\n",
      "Train | Loss: 0.0006 | Acc: 97.67\n",
      "Test  | Loss: 0.0025 | Acc: 91.06\n",
      "\n",
      "Epoch: 124\n",
      "Train | Loss: 0.0005 | Acc: 97.77\n",
      "Test  | Loss: 0.0026 | Acc: 91.31\n",
      "\n",
      "Epoch: 125\n",
      "Train | Loss: 0.0005 | Acc: 97.73\n",
      "Test  | Loss: 0.0026 | Acc: 91.01\n",
      "\n",
      "Epoch: 126\n",
      "Train | Loss: 0.0005 | Acc: 97.78\n",
      "Test  | Loss: 0.0026 | Acc: 91.08\n",
      "\n",
      "Epoch: 127\n",
      "Train | Loss: 0.0005 | Acc: 97.7\n",
      "Test  | Loss: 0.0026 | Acc: 91.16\n",
      "\n",
      "Epoch: 128\n",
      "Train | Loss: 0.0005 | Acc: 98.03\n",
      "Test  | Loss: 0.0026 | Acc: 90.99\n",
      "\n",
      "Epoch: 129\n",
      "Train | Loss: 0.0004 | Acc: 98.14\n",
      "Test  | Loss: 0.0025 | Acc: 91.29\n",
      "\n",
      "Epoch: 130\n",
      "Train | Loss: 0.0004 | Acc: 98.23\n",
      "Test  | Loss: 0.0026 | Acc: 91.25\n",
      "\n",
      "Epoch: 131\n",
      "Train | Loss: 0.0004 | Acc: 98.16\n",
      "Test  | Loss: 0.0027 | Acc: 91.1\n",
      "\n",
      "Epoch: 132\n",
      "Train | Loss: 0.0004 | Acc: 98.29\n",
      "Test  | Loss: 0.0026 | Acc: 91.2\n",
      "\n",
      "Epoch: 133\n",
      "Train | Loss: 0.0004 | Acc: 98.26\n",
      "Test  | Loss: 0.0025 | Acc: 91.26\n",
      "\n",
      "Epoch: 134\n",
      "Train | Loss: 0.0004 | Acc: 98.27\n",
      "Test  | Loss: 0.0026 | Acc: 91.28\n",
      "\n",
      "Epoch: 135\n",
      "Train | Loss: 0.0004 | Acc: 98.26\n",
      "Test  | Loss: 0.0026 | Acc: 91.21\n",
      "\n",
      "Epoch: 136\n",
      "Train | Loss: 0.0004 | Acc: 98.3\n",
      "Test  | Loss: 0.0026 | Acc: 91.22\n",
      "\n",
      "Epoch: 137\n",
      "Train | Loss: 0.0004 | Acc: 98.23\n",
      "Test  | Loss: 0.0026 | Acc: 91.06\n",
      "\n",
      "Epoch: 138\n",
      "Train | Loss: 0.0004 | Acc: 98.13\n",
      "Test  | Loss: 0.0026 | Acc: 91.3\n",
      "\n",
      "Epoch: 139\n",
      "Train | Loss: 0.0004 | Acc: 98.27\n",
      "Test  | Loss: 0.0026 | Acc: 91.16\n",
      "\n",
      "Epoch: 140\n",
      "Train | Loss: 0.0004 | Acc: 98.29\n",
      "Test  | Loss: 0.0026 | Acc: 91.27\n",
      "\n",
      "Epoch: 141\n",
      "Train | Loss: 0.0004 | Acc: 98.16\n",
      "Test  | Loss: 0.0027 | Acc: 91.18\n",
      "\n",
      "Epoch: 142\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.08\n",
      "\n",
      "Epoch: 143\n",
      "Train | Loss: 0.0004 | Acc: 98.29\n",
      "Test  | Loss: 0.0026 | Acc: 91.23\n",
      "\n",
      "Epoch: 144\n",
      "Train | Loss: 0.0004 | Acc: 98.38\n",
      "Test  | Loss: 0.0027 | Acc: 91.09\n",
      "\n",
      "Epoch: 145\n",
      "Train | Loss: 0.0004 | Acc: 98.22\n",
      "Test  | Loss: 0.0026 | Acc: 91.17\n",
      "\n",
      "Epoch: 146\n",
      "Train | Loss: 0.0004 | Acc: 98.28\n",
      "Test  | Loss: 0.0026 | Acc: 91.11\n",
      "\n",
      "Epoch: 147\n",
      "Train | Loss: 0.0004 | Acc: 98.31\n",
      "Test  | Loss: 0.0026 | Acc: 91.29\n",
      "\n",
      "Epoch: 148\n",
      "Train | Loss: 0.0004 | Acc: 98.34\n",
      "Test  | Loss: 0.0026 | Acc: 91.21\n",
      "\n",
      "Epoch: 149\n",
      "Train | Loss: 0.0004 | Acc: 98.27\n",
      "Test  | Loss: 0.0026 | Acc: 91.13\n",
      "\n",
      "Epoch: 150\n",
      "Train | Loss: 0.0004 | Acc: 98.35\n",
      "Test  | Loss: 0.0026 | Acc: 91.11\n",
      "\n",
      "Epoch: 151\n",
      "Train | Loss: 0.0004 | Acc: 98.28\n",
      "Test  | Loss: 0.0026 | Acc: 91.15\n",
      "\n",
      "Epoch: 152\n",
      "Train | Loss: 0.0004 | Acc: 98.28\n",
      "Test  | Loss: 0.0026 | Acc: 91.14\n",
      "\n",
      "Epoch: 153\n",
      "Train | Loss: 0.0004 | Acc: 98.39\n",
      "Test  | Loss: 0.0026 | Acc: 91.07\n",
      "\n",
      "Epoch: 154\n",
      "Train | Loss: 0.0004 | Acc: 98.38\n",
      "Test  | Loss: 0.0026 | Acc: 91.13\n",
      "\n",
      "Epoch: 155\n",
      "Train | Loss: 0.0004 | Acc: 98.33\n",
      "Test  | Loss: 0.0026 | Acc: 91.29\n",
      "\n",
      "Epoch: 156\n",
      "Train | Loss: 0.0004 | Acc: 98.24\n",
      "Test  | Loss: 0.0026 | Acc: 91.19\n",
      "\n",
      "Epoch: 157\n",
      "Train | Loss: 0.0004 | Acc: 98.35\n",
      "Test  | Loss: 0.0026 | Acc: 91.24\n",
      "\n",
      "Epoch: 158\n",
      "Train | Loss: 0.0004 | Acc: 98.33\n",
      "Test  | Loss: 0.0026 | Acc: 91.08\n",
      "\n",
      "Epoch: 159\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0027 | Acc: 91.17\n",
      "\n",
      "Epoch: 160\n",
      "Train | Loss: 0.0004 | Acc: 98.36\n",
      "Test  | Loss: 0.0026 | Acc: 91.3\n",
      "\n",
      "Epoch: 161\n",
      "Train | Loss: 0.0004 | Acc: 98.41\n",
      "Test  | Loss: 0.0026 | Acc: 91.13\n",
      "\n",
      "Epoch: 162\n",
      "Train | Loss: 0.0004 | Acc: 98.21\n",
      "Test  | Loss: 0.0026 | Acc: 91.22\n",
      "\n",
      "Epoch: 163\n",
      "Train | Loss: 0.0004 | Acc: 98.39\n",
      "Test  | Loss: 0.0026 | Acc: 91.25\n",
      "\n",
      "Epoch: 164\n",
      "Train | Loss: 0.0004 | Acc: 98.38\n",
      "Test  | Loss: 0.0026 | Acc: 91.26\n",
      "\n",
      "Epoch: 165\n",
      "Train | Loss: 0.0004 | Acc: 98.3\n",
      "Test  | Loss: 0.0026 | Acc: 91.1\n",
      "\n",
      "Epoch: 166\n",
      "Train | Loss: 0.0004 | Acc: 98.26\n",
      "Test  | Loss: 0.0027 | Acc: 91.21\n",
      "\n",
      "Epoch: 167\n",
      "Train | Loss: 0.0004 | Acc: 98.24\n",
      "Test  | Loss: 0.0026 | Acc: 91.19\n",
      "\n",
      "Epoch: 168\n",
      "Train | Loss: 0.0004 | Acc: 98.28\n",
      "Test  | Loss: 0.0026 | Acc: 91.22\n",
      "\n",
      "Epoch: 169\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.12\n",
      "\n",
      "Epoch: 170\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.15\n",
      "\n",
      "Epoch: 171\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.18\n",
      "\n",
      "Epoch: 172\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.11\n",
      "\n",
      "Epoch: 173\n",
      "Train | Loss: 0.0004 | Acc: 98.36\n",
      "Test  | Loss: 0.0026 | Acc: 91.21\n",
      "\n",
      "Epoch: 174\n",
      "Train | Loss: 0.0004 | Acc: 98.24\n",
      "Test  | Loss: 0.0026 | Acc: 91.17\n",
      "\n",
      "Epoch: 175\n",
      "Train | Loss: 0.0004 | Acc: 98.3\n",
      "Test  | Loss: 0.0026 | Acc: 91.26\n",
      "\n",
      "Epoch: 176\n",
      "Train | Loss: 0.0004 | Acc: 98.31\n",
      "Test  | Loss: 0.0027 | Acc: 91.16\n",
      "\n",
      "Epoch: 177\n",
      "Train | Loss: 0.0004 | Acc: 98.34\n",
      "Test  | Loss: 0.0026 | Acc: 91.09\n",
      "\n",
      "Epoch: 178\n",
      "Train | Loss: 0.0004 | Acc: 98.3\n",
      "Test  | Loss: 0.0026 | Acc: 91.17\n",
      "\n",
      "Epoch: 179\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.25\n",
      "\n",
      "Epoch: 180\n",
      "Train | Loss: 0.0004 | Acc: 98.31\n",
      "Test  | Loss: 0.0027 | Acc: 91.1\n",
      "\n",
      "Epoch: 181\n",
      "Train | Loss: 0.0004 | Acc: 98.36\n",
      "Test  | Loss: 0.0026 | Acc: 91.19\n",
      "\n",
      "Epoch: 182\n",
      "Train | Loss: 0.0004 | Acc: 98.32\n",
      "Test  | Loss: 0.0026 | Acc: 91.1\n",
      "\n",
      "Epoch: 183\n",
      "Train | Loss: 0.0004 | Acc: 98.38\n",
      "Test  | Loss: 0.0026 | Acc: 91.21\n",
      "\n",
      "Epoch: 184\n",
      "Train | Loss: 0.0004 | Acc: 98.41\n",
      "Test  | Loss: 0.0026 | Acc: 91.17\n",
      "\n",
      "Epoch: 185\n",
      "Train | Loss: 0.0004 | Acc: 98.46\n",
      "Test  | Loss: 0.0026 | Acc: 91.28\n",
      "\n",
      "Epoch: 186\n",
      "Train | Loss: 0.0004 | Acc: 98.35\n",
      "Test  | Loss: 0.0026 | Acc: 91.09\n",
      "\n",
      "Epoch: 187\n",
      "Train | Loss: 0.0004 | Acc: 98.31\n",
      "Test  | Loss: 0.0026 | Acc: 91.21\n",
      "\n",
      "Epoch: 188\n",
      "Train | Loss: 0.0004 | Acc: 98.42\n",
      "Test  | Loss: 0.0026 | Acc: 91.17\n",
      "\n",
      "Epoch: 189\n",
      "Train | Loss: 0.0004 | Acc: 98.27\n",
      "Test  | Loss: 0.0026 | Acc: 91.17\n",
      "\n",
      "Epoch: 190\n",
      "Train | Loss: 0.0004 | Acc: 98.26\n",
      "Test  | Loss: 0.0026 | Acc: 91.28\n",
      "\n",
      "Epoch: 191\n",
      "Train | Loss: 0.0004 | Acc: 98.33\n",
      "Test  | Loss: 0.0026 | Acc: 91.16\n",
      "\n",
      "Epoch: 192\n",
      "Train | Loss: 0.0004 | Acc: 98.29\n",
      "Test  | Loss: 0.0026 | Acc: 91.19\n",
      "\n",
      "Epoch: 193\n",
      "Train | Loss: 0.0004 | Acc: 98.42\n",
      "Test  | Loss: 0.0026 | Acc: 91.25\n",
      "\n",
      "Epoch: 194\n",
      "Train | Loss: 0.0004 | Acc: 98.39\n",
      "Test  | Loss: 0.0026 | Acc: 91.08\n",
      "\n",
      "Epoch: 195\n",
      "Train | Loss: 0.0004 | Acc: 98.35\n",
      "Test  | Loss: 0.0026 | Acc: 91.26\n",
      "\n",
      "Epoch: 196\n",
      "Train | Loss: 0.0004 | Acc: 98.3\n",
      "Test  | Loss: 0.0026 | Acc: 91.23\n",
      "\n",
      "Epoch: 197\n",
      "Train | Loss: 0.0004 | Acc: 98.38\n",
      "Test  | Loss: 0.0026 | Acc: 91.14\n",
      "\n",
      "Epoch: 198\n",
      "Train | Loss: 0.0004 | Acc: 98.43\n",
      "Test  | Loss: 0.0026 | Acc: 90.99\n",
      "\n",
      "Epoch: 199\n",
      "Train | Loss: 0.0004 | Acc: 98.37\n",
      "Test  | Loss: 0.0026 | Acc: 91.2\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(start_epoch +1 , start_epoch + 201):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    lrs.append(optimizer.param_groups[0]['lr'])\n",
    "    scheduler.step(test_accs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa18fc1a-60f6-4f4c-9303-67efb42831de",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize = (10,3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(len(train_losses)), train_losses, label = 'Train loss')\n",
    "plt.plot(range(len(test_losses)), test_losses, label = 'Val loss')\n",
    "plt.plot(range(len(lrs)), lrs, label = 'learning rate')\n",
    "plt.title('Loss curve')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(len(train_losses)), train_accs, label = 'Train acc')\n",
    "plt.plot(range(len(test_losses)), test_accs, label = 'Val acc')\n",
    "plt.plot(range(len(lrs)), lrs, label = 'learning rate')\n",
    "plt.title('Accuracy curve')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35dbeb-289f-4f25-840b-a375da414b6d",
   "metadata": {},
   "source": [
    "The loss should have divided by the number of samples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c711c19-7dac-4e56-8d31-a1d8d545ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6760c48f-bcfd-47a0-b071-a214c7ba13a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
